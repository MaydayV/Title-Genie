import streamlit as st
import pandas as pd
import os
import re
import json
import time
from utils.file_handler import load_file, export_excel
from utils.prompt_builder import build_prompt
from utils.text_gen import generate_text
from utils.validator import (
    validate_brand, 
    check_duplication, 
    calculate_seo_score, 
    fix_acronyms, 
    remove_filler_words,
    remove_punctuation
)
from utils.title_history import TitleHistoryManager

# Load environment variables (Local dev)
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# Initialize browser localStorage (Optional)
class MockLocalStorage:
    def getItem(self, key): return None
    def setItem(self, key, value): pass

try:
    from streamlit_local_storage import LocalStorage
    localStorage = LocalStorage()
except ImportError:
    localStorage = MockLocalStorage()

# --- Helper Functions for Config Persistence (Browser LocalStorage) ---
LOCAL_STORAGE_KEY = "title_genie_config"

def load_config_from_browser():
    """Load config from browser localStorage"""
    try:
        data = localStorage.getItem(LOCAL_STORAGE_KEY)
        if data:
            return json.loads(data) if isinstance(data, str) else data
    except Exception:
        pass
    return {}

def save_config_to_browser(config):
    """Save config to browser localStorage"""
    try:
        localStorage.setItem(LOCAL_STORAGE_KEY, json.dumps(config))
    except Exception:
        pass

st.set_page_config(page_title="Title Genie æ ‡é¢˜ç²¾çµ", page_icon="ğŸ§", layout="wide")

def main():
    st.title("ğŸ§ Title Genie æ ‡é¢˜ç²¾çµ (Beta)")
    st.markdown("é˜¿é‡Œå›½é™…ç«™æ ‡é¢˜è‡ªåŠ¨åŒ–ç”Ÿæˆå·¥å…·")

    # Load config from browser localStorage
    # local_config = load_config_from_browser() # This line is moved inside main() and show_settings_dialog()

    # Initialize History Manager with browser localStorage
    # history_manager = TitleHistoryManager(local_storage=localStorage) # This line is moved inside main()

@st.dialog("âš™ï¸ è®¾ç½® (Configuration)", width="large")
def show_settings_dialog(history_manager):
    # API Key Management
    local_config = load_config_from_browser()
    
    st.subheader("ğŸ”‘ API è®¾ç½®")
    api_key_input = st.text_input(
        "DashScope API Key (é€šä¹‰åƒé—®)", 
        value=st.session_state.get('api_key', ''),
        type="password",
        help="è¯·ä»é˜¿é‡Œäº‘ DashScope æ§åˆ¶å°è·å– API Key",
        key="api_key_dialog"
    )
    
    # Update session state & auto-save to browser localStorage on change
    if api_key_input != st.session_state.get('api_key'):
        st.session_state['api_key'] = api_key_input
        local_config["api_key"] = api_key_input
        save_config_to_browser(local_config)
        st.toast("API Key å·²ä¿å­˜", icon="ğŸ’¾")

    # Model Selection
    model_name = st.selectbox(
        "é€‰æ‹©æ¨¡å‹ (Model)",
        options=["qwen-flash", "qwen-plus", "qwen-turbo", "qwen-max"],
        index=["qwen-flash", "qwen-plus", "qwen-turbo", "qwen-max"].index(st.session_state.get('model_name', 'qwen-flash')),
        help="æ¨èä½¿ç”¨ qwen-flash ä»¥è·å¾—æœ€å¿«çš„ç”Ÿæˆé€Ÿåº¦ã€‚",
        key="model_dialog"
    )
    st.session_state['model_name'] = model_name

    # Keyword Positioning
    st.divider()
    st.subheader("ğŸ“ å…³é”®è¯ä½ç½®è®¾ç½®")
    pos_options = ["å‰ (Front)", "ä¸­ (Middle)", "å°¾ (End)"]
    
    col_p1, col_p2, col_p3 = st.columns(3)
    with col_p1:
        st.session_state['pos_brand'] = st.selectbox("å“ç‰Œè¯", pos_options, 
                                                    index=pos_options.index(st.session_state.get('pos_brand', "å‰ (Front)")), 
                                                    key="brand_pos_dialog")
    with col_p2:
        st.session_state['pos_main'] = st.selectbox("ä¸»è¯", pos_options, 
                                                   index=pos_options.index(st.session_state.get('pos_main', "å‰ (Front)")), 
                                                   key="main_pos_dialog")
    with col_p3:
        st.session_state['pos_core'] = st.selectbox("æ ¸å¿ƒè¯", pos_options, 
                                                   index=pos_options.index(st.session_state.get('pos_core', "å°¾ (End)")), 
                                                   key="core_pos_dialog")

    # Strategy Selection
    st.divider()
    st.subheader("ğŸ¤– ç”Ÿæˆç­–ç•¥è®¾ç½®")
    mode_index = 1 if st.session_state.get('selected_mode_label', "Mode B (è¥é”€æ¨¡å¼)") == "Mode B (è¥é”€æ¨¡å¼)" else 0
    mode = st.radio(
        "é€‰æ‹©ç”Ÿæˆæ¨¡å¼",
        ("Mode A (ä¸¥æ ¼æ¨¡å¼)", "Mode B (è¥é”€æ¨¡å¼)"),
        index=mode_index,
        help="é€‰æ‹© 'Mode A' è¿›è¡Œä¸¥æ ¼æ ¼å¼åŒ–ï¼Œæˆ–é€‰æ‹© 'Mode B' ä»¥è·å¾—æ›´å¥½çš„ç‚¹å‡»ç‡ã€‚",
        key="mode_dialog"
    )
    st.session_state['selected_mode_label'] = mode
    
    # Generation Count
    num_titles = st.slider("æ¯ä¸ªäº§å“ç”Ÿæˆæ ‡é¢˜æ•°é‡", 1, 10, st.session_state.get('num_titles', 5), key="num_titles_dialog")
    st.session_state['num_titles'] = num_titles

    # History Management
    st.divider()
    st.subheader("ğŸ” å†å²åº“ç®¡ç†")
    stats = history_manager.get_stats()
    st.caption(f"å½“å‰å†å²åº“å·²æœ‰æ ‡é¢˜: {stats['total_titles']} æ¡")
    if st.button("æ¸…é™¤å†å²åº“ (Clear History)", type="secondary", key="clear_history_dialog"):
            history_manager.clear_history()
            history_manager.save_history()
            st.toast("å†å²åº“å·²æ¸…ç©º")
            st.rerun()

def main():
    # Header with Settings button
    col_title, col_settings = st.columns([8, 1])
    with col_title:
        st.title("ğŸ§ Title Genie æ ‡é¢˜ç²¾çµ (Beta)")
        st.markdown("é˜¿é‡Œå›½é™…ç«™æ ‡é¢˜è‡ªåŠ¨åŒ–ç”Ÿæˆå·¥å…·")
    with col_settings:
        st.write("") # Padding
        if st.button("âš™ï¸ è®¾ç½®", use_container_width=True):
            show_settings_dialog(history_manager)

    # Initialize session state defaults if not present
    if 'model_name' not in st.session_state: st.session_state['model_name'] = "qwen-flash"
    if 'pos_brand' not in st.session_state: st.session_state['pos_brand'] = "å‰ (Front)"
    if 'pos_main' not in st.session_state: st.session_state['pos_main'] = "å‰ (Front)"
    if 'pos_core' not in st.session_state: st.session_state['pos_core'] = "å°¾ (End)"
    if 'selected_mode_label' not in st.session_state: st.session_state['selected_mode_label'] = "Mode B (è¥é”€æ¨¡å¼)"
    if 'num_titles' not in st.session_state: st.session_state['num_titles'] = 5

    # Load config from browser localStorage for initial API key
    local_config = load_config_from_browser()

    # Initialize History Manager with browser localStorage
    history_manager = TitleHistoryManager(local_storage=localStorage)

    # API Key Initial Sync
    if 'api_key' not in st.session_state:
        env_key = ""
        try:
            env_key = st.secrets.get("DASHSCOPE_API_KEY", "")
        except Exception: pass
        if not env_key:
            env_key = os.getenv("DASHSCOPE_API_KEY", "")
        st.session_state['api_key'] = env_key if env_key else local_config.get("api_key", "")

    # Derived values for logic
    keyword_positions = {
        "Brand": st.session_state['pos_brand'],
        "Main Keyword": st.session_state['pos_main'],
        "Core Keyword": st.session_state['pos_core']
    }
    selected_mode = "Mode A" if "Mode A" in st.session_state['selected_mode_label'] else "Mode B"
    num_titles = st.session_state['num_titles']
    api_key_input = st.session_state['api_key']
    model_name = st.session_state['model_name']

    # --- Main Content ---
    
    # 1. Product Data Upload
    uploaded_file = st.file_uploader("ä¸Šä¼ äº§å“èµ„æ–™è¡¨ (æ”¯æŒ Excel æˆ– CSV)", type=["xlsx", "csv"], key="main_file")
    
    st.divider()

    # 2. Performance Data (Optional)
    performance_context = ""
    with st.expander("ğŸ“ˆ æ™ºèƒ½æ•°æ®åˆ†æ (å¯é€‰)", expanded=False):
        st.write("ä¸Šä¼ é˜¿é‡Œåå°çš„â€œå•†å“åˆ†æâ€æŠ¥è¡¨ (Excel)ï¼ŒAI å°†è‡ªåŠ¨åˆ†æé«˜ç‚¹å‡»è¯å¹¶åœ¨ç”Ÿæˆæ–°æ ‡é¢˜æ—¶å‚è€ƒã€‚")
        perf_file = st.file_uploader("ä¸Šä¼ æ•ˆæœæŠ¥è¡¨", type=["xlsx"], key="perf")
        
        if perf_file:
            from utils.analyzer import analyze_performance
            with st.spinner("æ­£åœ¨åˆ†æå†å²è¡¨ç°æ•°æ®..."):
                performance_context = analyze_performance(perf_file)
                st.info(performance_context)
    
    if uploaded_file:
        try:
            df = load_file(uploaded_file)
            st.success(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å…±åŠ è½½ {len(df)} è¡Œæ•°æ®ã€‚")
            
            with st.expander("æ•°æ®é¢„è§ˆ", expanded=True):
                st.dataframe(df.head())
            
            # Column Validation
            df.columns = df.columns.str.strip()
            required_columns = ['Brand', 'Main Keyword', 'Core Keyword']
            missing_cols = [col for col in required_columns if col not in df.columns]
            
            if missing_cols:
                st.error(f"ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing_cols)}")
                return

            # --- Resume / Checkpoint Logic ---
            if 'processed_indices' not in st.session_state:
                st.session_state['processed_indices'] = set()
                st.session_state['results_list'] = []

            processed_count = len(st.session_state['processed_indices'])
            total_rows = len(df)
            
            # --- Starred Fields Selection ---
            st.divider()
            st.subheader("â­ æ˜Ÿæ ‡å­—æ®µè®¾ç½®")
            st.caption("é€‰æ‹©æœ€å¤š2ä¸ªå­—æ®µï¼Œå…¶å†…å®¹å°†å¼ºåˆ¶åŒ…å«åœ¨æ ‡é¢˜ä¸­ï¼ˆå¯AIä¼˜åŒ–ï¼‰ã€‚")
            
            # Exclude mandatory keywords from selection
            exclude_keywords = ['Brand', 'Main Keyword', 'Core Keyword', 'Generated Titles', 'Original Row ID']
            available_star_cols = [c for c in df.columns if c not in exclude_keywords and c.strip() != '']
            
            starred_fields = st.multiselect(
                "é€‰æ‹©æ˜Ÿæ ‡å­—æ®µ (æœ€å¤š2ä¸ª)",
                options=available_star_cols,
                max_selections=2,
                key="starred_fields_select",
                help="æ‰€é€‰å­—æ®µçš„å†…å®¹ä¼šè¢«åŠ å…¥æç¤ºè¯ï¼Œè¦æ±‚AIå¿…é¡»ä½“ç°åœ¨æ ‡é¢˜ä¸­ã€‚"
            )

            
            # --- Generation Trigger ---
            btn_label = "å¼€å§‹ç”Ÿæˆæ ‡é¢˜" if processed_count == 0 else f"ç»§ç»­ç”Ÿæˆ (å·²å®Œæˆ {processed_count}/{total_rows})"
            
            if st.button(btn_label, type="primary"):
                if not api_key_input:
                    st.error("è¯·æä¾› API Keyã€‚")
                    return
                
                progress_bar = st.progress(processed_count / total_rows)
                status_text = st.empty()
                time_estimator = st.empty()
                
                start_time = time.time()
                
                # Iterate
                for index, row in df.iterrows():
                    if index in st.session_state['processed_indices']:
                        continue # Skip already processed
                    
                    # Estimate remaining time
                    processed_in_session = len(st.session_state['processed_indices']) - processed_count + 1 # simplistic
                    elapsed = time.time() - start_time
                    if processed_in_session > 1:
                        avg_time = elapsed / (processed_in_session - 1)
                        remaining = (total_rows - len(st.session_state['processed_indices'])) * avg_time
                        time_estimator.caption(f"é¢„è®¡å‰©ä½™æ—¶é—´: {int(remaining // 60)}åˆ† {int(remaining % 60)}ç§’")

                    main_kw_display = row.get('Main Keyword', 'æœªçŸ¥äº§å“')
                    if pd.isna(main_kw_display): main_kw_display = 'æœªçŸ¥äº§å“'
                    
                    status_text.markdown(f"**æ­£åœ¨å¤„ç† ({index + 1}/{total_rows})**: `{main_kw_display}`")
                    
                    # Build Prompt
                    role_instruction = "Role: You are an Alibaba International Station SEO expert specializing in high-converting product titles for global markets."
                    prompt = build_prompt(
                        row, 
                        selected_mode, 
                        extra_context=performance_context,
                        keyword_positions=keyword_positions,
                        starred_fields=starred_fields
                    )
                    full_prompt = f"{prompt}\n\nTask: Generate {num_titles} distinct, professional titles for this product. Output them as a numbered list (1. Title...)."
                    
                    # Call API
                    generated_content = generate_text(full_prompt, api_key_input, model_name)
                    
                    # Parse Content
                    lines = generated_content.split('\n')
                    generated_titles_for_this_row = [] 
                    
                    for line in lines:
                        line = line.strip()
                        if not line: continue
                        
                        clean_title = re.sub(r'^\d+\.?\s*', '', line)
                        if len(clean_title) < 10: continue

                        # 0. Post-AI Cleanup & Normalization
                        clean_title = remove_punctuation(clean_title)  # Remove commas/periods FIRST
                        clean_title = remove_filler_words(clean_title)
                        clean_title = fix_acronyms(clean_title)

                        # 1. Brand Validation
                        clean_title, fixed = validate_brand(clean_title, row.get('Brand', ''))
                        
                        # 2. Duplicate Detection (Batch + History)
                        # Check batch dupes
                        is_dup_batch, _ = check_duplication(clean_title, generated_titles_for_this_row)
                        if is_dup_batch: continue
                        
                        # Check history dupes (Cross-Library)
                        is_dup_hist, score_hist, sim_title = history_manager.check_similarity(clean_title, threshold=0.8)
                        
                        # Note: We might still want to show it but flag it? Or filter it?
                        # For now, let's filter if it's a strong match > 0.9, otherwise just warn in notes
                        dup_note = ""
                        if is_dup_hist:
                             if score_hist > 0.95:
                                 continue # Skip identicals
                             dup_note = f" (ä¸å†å²æ ‡é¢˜ç›¸ä¼¼åº¦ {score_hist:.0%})"

                        generated_titles_for_this_row.append(clean_title)

                        # 3. SEO Scoring
                        seo_score, seo_notes = calculate_seo_score(
                            clean_title, 
                            row.get('Brand', ''), 
                            row.get('Main Keyword', ''), 
                            row.get('Core Keyword', '')
                        )
                        
                        # --- AI Polishing Loop (Self-Correction) ---
                        attempts = 0
                        max_attempts = 2
                        while seo_score < 100 and attempts < max_attempts:
                            attempts += 1
                            polish_prompt = f"""
{role_instruction}
The following title needs optimization to reach a perfect SEO score (100).
Current Title: "{clean_title}"
Current Character Count: {len(clean_title)}
REQUIRED Character Count: 80 - 120 (STRICT HARD LIMIT: DO NOT EXCEED 120)
Faults Identified: {seo_notes}
Mandatory Keywords: "{row.get('Brand', '')}", "{row.get('Main Keyword', '')}", "{row.get('Core Keyword', '')}"

Task: Rewrite the title to fix all faults. 
If it's too long, you MUST REMOVE non-essential descriptive words or specifications.
The new title MUST:
1. Start with "{row.get('Brand', '')} {row.get('Main Keyword', '')}"
2. Include "{row.get('Core Keyword', '')}"
3. Be between 80 - 120 characters total.
Output ONLY the new title.
"""
                            polished_title = generate_text(polish_prompt, api_key_input, model_name).strip()
                            polished_title = re.sub(r'^["\']|["\']$', '', polished_title) # Remove quotes
                            
                            # Re-Validate
                            new_score, new_notes = calculate_seo_score(
                                polished_title, 
                                row.get('Brand', ''), 
                                row.get('Main Keyword', ''), 
                                row.get('Core Keyword', '')
                            )
                            
                            if new_score >= seo_score:
                                clean_title = polished_title
                                seo_score = new_score
                                seo_notes = f"[Polished V{attempts}] {new_notes}"
                                if seo_score == 100:
                                    break

                        result_row = {
                            "åŸè¡Œå· (Row ID)": index + 1,
                            "å“ç‰Œ (Brand)": row.get('Brand', ''),
                            "ä¸»è¯ (Main Keyword)": row.get('Main Keyword', ''),
                            "æ ¸å¿ƒè¯ (Core Keyword)": row.get('Core Keyword', ''),
                            "AI ç”Ÿæˆæ ‡é¢˜ (AI Suggestions)": clean_title,
                            "SEO å¾—åˆ†": seo_score,
                            "æ‰£åˆ†åŸå› ": seo_notes + dup_note
                        }
                        st.session_state['results_list'].append(result_row)
                        
                        # ** Add to History Immediately **
                        history_manager.add_title(clean_title, brand=row.get('Brand', ''), product_id=f"Row-{index+1}")

                    # Mark as processed
                    st.session_state['processed_indices'].add(index)
                    progress_bar.progress(len(st.session_state['processed_indices']) / total_rows)
                    
                    # Auto-save history every row (safer)
                    history_manager.save_history()
                
                status_text.success("ç”Ÿæˆå®Œæˆï¼")
                time_estimator.empty()
                
        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {e}")
            st.exception(e)

    # --- Results & Export ---
    if 'results_list' in st.session_state and st.session_state['results_list']:
        st.divider()
        st.subheader("ç”Ÿæˆç»“æœ")
        
        # Convert list to DF for logic
        results_df = pd.DataFrame(st.session_state['results_list'])
        
        edited_df = st.data_editor(
            results_df,
            num_rows="dynamic",
            use_container_width=True,
            height=400
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
             # Download
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ç»“æœ (Excel)",
                data=export_excel(edited_df),
                file_name="title_genie_results.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰ä»»åŠ¡ç»“æœ", help="æ¸…é™¤é¡µé¢ç¼“å­˜å’Œè¿›åº¦ï¼Œå¼€å§‹æ–°ä»»åŠ¡"):
                st.session_state['results_list'] = []
                st.session_state['processed_indices'] = set()
                st.rerun()

if __name__ == "__main__":
    main()
