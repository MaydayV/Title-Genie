import streamlit as st
import pandas as pd
import os
import re
from dotenv import load_dotenv
from utils.file_handler import load_file, export_excel
from utils.prompt_builder import build_prompt
from utils.text_gen import generate_text
from utils.validator import validate_brand, check_duplication, calculate_seo_score

# Load environment variables
load_dotenv()

# --- Helper Functions for Config Persistence ---
CONFIG_FILE = ".title_genie_config.json"
import json
import time
from utils.title_history import TitleHistoryManager

def load_config():
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, 'r') as f:
                return json.load(f)
        except:
            pass
    return {}

def save_config(config):
    try:
        with open(CONFIG_FILE, 'w') as f:
            json.dump(config, f)
    except:
        pass

st.set_page_config(page_title="Title Genie æ ‡é¢˜ç²¾çµ", page_icon="ğŸ§", layout="wide")

def main():
    st.title("ğŸ§ Title Genie æ ‡é¢˜ç²¾çµ (Beta)")
    st.markdown("é˜¿é‡Œå›½é™…ç«™æ ‡é¢˜è‡ªåŠ¨åŒ–ç”Ÿæˆå·¥å…·")

    # Load local config
    local_config = load_config()

    # Initialize History Manager
    history_manager = TitleHistoryManager()

    # --- Sidebar Configuration ---
    with st.sidebar:
        st.header("è®¾ç½® (Configuration)")
        
        # API Key Management
        if 'api_key' not in st.session_state:
            # Try env var first, then local config
            env_key = os.getenv("DASHSCOPE_API_KEY", "")
            st.session_state['api_key'] = env_key if env_key else local_config.get("api_key", "")
            
        api_key_input = st.text_input(
            "DashScope API Key (é€šä¹‰åƒé—®)", 
            value=st.session_state['api_key'],
            type="password",
            help="è¯·ä»é˜¿é‡Œäº‘ DashScope æ§åˆ¶å°è·å– API Key",
            key="api_key_input"
        )
        # Update session state & auto-save to local config on change
        if api_key_input != st.session_state['api_key']:
            st.session_state['api_key'] = api_key_input
            local_config["api_key"] = api_key_input
            save_config(local_config)
            st.toast("API Key å·²ä¿å­˜", icon="ğŸ’¾")
        
        # Model Selection
        st.subheader("æ¨¡å‹è®¾ç½®")
        model_name = st.selectbox(
            "é€‰æ‹©æ¨¡å‹ (Model)",
            options=["qwen-flash", "qwen-plus", "qwen-turbo", "qwen-max"],
            index=0, # Default to qwen-flash
            help="æ¨èä½¿ç”¨ qwen-flash ä»¥è·å¾—æœ€å¿«çš„ç”Ÿæˆé€Ÿåº¦ã€‚"
        )

        # Strategy Selection
        st.subheader("ç”Ÿæˆç­–ç•¥è®¾ç½®")
        with st.expander("â„¹ï¸ ç­–ç•¥è¯´æ˜æŒ‡å—"):
            st.markdown("""
            **æ¨¡å¼ A (ä¸¥æ ¼åˆè§„æ¨¡å¼):**
            - **é€‚ç”¨åœºæ™¯:** æ ‡å‡†åŒ–äº§å“ç›®å½•ï¼Œå¯¹æ ¼å¼è¦æ±‚ä¸¥æ ¼ã€‚
            - **é€»è¾‘:** ä¸¥æ ¼éµå¾ª `å“ç‰Œ + è§„æ ¼/å±æ€§ + æ ¸å¿ƒè¯` çš„æ’åºç»“æ„ã€‚
            
            **æ¨¡å¼ B (é«˜ç‚¹å‡»/è¥é”€æ¨¡å¼):**
            - **é€‚ç”¨åœºæ™¯:** è¿½æ±‚é«˜ç‚¹å‡»ç‡ (CTR) å’Œè¥é”€æ•ˆæœã€‚
            - **é€»è¾‘:** è®© AI åœ¨ä¿ç•™å¿…é€‰å…³é”®è¯çš„å‰æä¸‹ï¼Œå‘æŒ¥åˆ›æ„ç¼–å†™ç¬¦åˆæ¯è¯­ä¹ æƒ¯ã€æ›´æœ‰å¸å¼•åŠ›çš„æ ‡é¢˜ã€‚
            """)
            
        mode = st.radio(
            "é€‰æ‹©ç”Ÿæˆæ¨¡å¼",
            ("Mode A (ä¸¥æ ¼æ¨¡å¼)", "Mode B (è¥é”€æ¨¡å¼)"),
            index=1,
            help="é€‰æ‹© 'Mode A' è¿›è¡Œä¸¥æ ¼æ ¼å¼åŒ–ï¼Œæˆ–é€‰æ‹© 'Mode B' ä»¥è·å¾—æ›´å¥½çš„ç‚¹å‡»ç‡ã€‚"
        )
        selected_mode = "Mode A" if "Mode A" in mode else "Mode B"
        
        # Generation Count
        num_titles = st.slider("æ¯ä¸ªäº§å“ç”Ÿæˆæ ‡é¢˜æ•°é‡", 1, 10, 5)

        # History Management
        st.divider()
        st.subheader("ğŸ” å†å²åº“ç®¡ç†")
        stats = history_manager.get_stats()
        st.caption(f"å½“å‰å†å²åº“å·²æœ‰æ ‡é¢˜: {stats['total_titles']} æ¡")
        if st.button("æ¸…é™¤å†å²åº“ (Clear History)", type="secondary"):
             history_manager.clear_history()
             history_manager.save_history()
             st.toast("å†å²åº“å·²æ¸…ç©º")
             st.rerun()

    # --- Main Content ---
    
    # 1. Product Data Upload
    uploaded_file = st.file_uploader("ä¸Šä¼ äº§å“èµ„æ–™è¡¨ (æ”¯æŒ Excel æˆ– CSV)", type=["xlsx", "csv"], key="main_file")
    
    st.divider()

    # 2. Performance Data (Optional)
    performance_context = ""
    with st.expander("ğŸ“ˆ æ™ºèƒ½æ•°æ®åˆ†æ (å¯é€‰)", expanded=False):
        st.write("ä¸Šä¼ é˜¿é‡Œåå°çš„â€œå•†å“åˆ†æâ€æŠ¥è¡¨ (Excel)ï¼ŒAI å°†è‡ªåŠ¨åˆ†æé«˜ç‚¹å‡»è¯å¹¶åœ¨ç”Ÿæˆæ–°æ ‡é¢˜æ—¶å‚è€ƒã€‚")
        perf_file = st.file_uploader("ä¸Šä¼ æ•ˆæœæŠ¥è¡¨", type=["xlsx"], key="perf")
        
        if perf_file:
            from utils.analyzer import analyze_performance
            with st.spinner("æ­£åœ¨åˆ†æå†å²è¡¨ç°æ•°æ®..."):
                performance_context = analyze_performance(perf_file)
                st.info(performance_context)
    
    if uploaded_file:
        try:
            df = load_file(uploaded_file)
            st.success(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼å…±åŠ è½½ {len(df)} è¡Œæ•°æ®ã€‚")
            
            with st.expander("æ•°æ®é¢„è§ˆ", expanded=True):
                st.dataframe(df.head())
            
            # Column Validation
            df.columns = df.columns.str.strip()
            required_columns = ['Brand', 'Main Keyword', 'Core Keyword']
            missing_cols = [col for col in required_columns if col not in df.columns]
            
            if missing_cols:
                st.error(f"ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing_cols)}")
                return

            # --- Resume / Checkpoint Logic ---
            if 'processed_indices' not in st.session_state:
                st.session_state['processed_indices'] = set()
                st.session_state['results_list'] = []

            processed_count = len(st.session_state['processed_indices'])
            total_rows = len(df)
            
            # --- Generation Trigger ---
            btn_label = "å¼€å§‹ç”Ÿæˆæ ‡é¢˜" if processed_count == 0 else f"ç»§ç»­ç”Ÿæˆ (å·²å®Œæˆ {processed_count}/{total_rows})"
            
            if st.button(btn_label, type="primary"):
                if not api_key_input:
                    st.error("è¯·æä¾› API Keyã€‚")
                    return
                
                progress_bar = st.progress(processed_count / total_rows)
                status_text = st.empty()
                time_estimator = st.empty()
                
                start_time = time.time()
                
                # Iterate
                for index, row in df.iterrows():
                    if index in st.session_state['processed_indices']:
                        continue # Skip already processed
                    
                    # Estimate remaining time
                    processed_in_session = len(st.session_state['processed_indices']) - processed_count + 1 # simplistic
                    elapsed = time.time() - start_time
                    if processed_in_session > 1:
                        avg_time = elapsed / (processed_in_session - 1)
                        remaining = (total_rows - len(st.session_state['processed_indices'])) * avg_time
                        time_estimator.caption(f"é¢„è®¡å‰©ä½™æ—¶é—´: {int(remaining // 60)}åˆ† {int(remaining % 60)}ç§’")

                    main_kw_display = row.get('Main Keyword', 'æœªçŸ¥äº§å“')
                    if pd.isna(main_kw_display): main_kw_display = 'æœªçŸ¥äº§å“'
                    
                    status_text.markdown(f"**æ­£åœ¨å¤„ç† ({index + 1}/{total_rows})**: `{main_kw_display}`")
                    
                    # Build Prompt
                    prompt = build_prompt(row, selected_mode, extra_context=performance_context)
                    full_prompt = f"{prompt}\n\nTask: Generate {num_titles} distinct, professional titles for this product. Output them as a numbered list (1. Title...)."
                    
                    # Call API
                    generated_content = generate_text(full_prompt, api_key_input, model_name)
                    
                    # Parse Content
                    lines = generated_content.split('\n')
                    generated_titles_for_this_row = [] 
                    
                    for line in lines:
                        line = line.strip()
                        if not line: continue
                        
                        clean_title = re.sub(r'^\d+\.?\s*', '', line)
                        if len(clean_title) < 10: continue

                        # 1. Brand Validation
                        clean_title, fixed = validate_brand(clean_title, row.get('Brand', ''))
                        
                        # 2. Duplicate Detection (Batch + History)
                        # Check batch dupes
                        is_dup_batch, _ = check_duplication(clean_title, generated_titles_for_this_row)
                        if is_dup_batch: continue
                        
                        # Check history dupes (Cross-Library)
                        is_dup_hist, score_hist, sim_title = history_manager.check_similarity(clean_title, threshold=0.8)
                        
                        # Note: We might still want to show it but flag it? Or filter it?
                        # For now, let's filter if it's a strong match > 0.9, otherwise just warn in notes
                        dup_note = ""
                        if is_dup_hist:
                             if score_hist > 0.95:
                                 continue # Skip identicals
                             dup_note = f" (ä¸å†å²æ ‡é¢˜ç›¸ä¼¼åº¦ {score_hist:.0%})"

                        generated_titles_for_this_row.append(clean_title)

                        # 3. SEO Scoring
                        seo_score, seo_notes = calculate_seo_score(
                            clean_title, 
                            row.get('Brand', ''), 
                            row.get('Main Keyword', ''), 
                            row.get('Core Keyword', '')
                        )
                        
                        result_row = {
                            "åŸè¡Œå· (Row ID)": index + 1,
                            "å“ç‰Œ (Brand)": row.get('Brand', ''),
                            "ä¸»è¯ (Main Keyword)": row.get('Main Keyword', ''),
                            "æ ¸å¿ƒè¯ (Core Keyword)": row.get('Core Keyword', ''),
                            "AI ç”Ÿæˆæ ‡é¢˜ (AI Suggestions)": clean_title,
                            "SEO å¾—åˆ†": seo_score,
                            "æ‰£åˆ†åŸå› ": seo_notes + dup_note
                        }
                        st.session_state['results_list'].append(result_row)
                        
                        # ** Add to History Immediately **
                        history_manager.add_title(clean_title, brand=row.get('Brand', ''), product_id=f"Row-{index+1}")

                    # Mark as processed
                    st.session_state['processed_indices'].add(index)
                    progress_bar.progress(len(st.session_state['processed_indices']) / total_rows)
                    
                    # Auto-save history every row (safer)
                    history_manager.save_history()
                
                status_text.success("ç”Ÿæˆå®Œæˆï¼")
                time_estimator.empty()
                
        except Exception as e:
            st.error(f"å‘ç”Ÿé”™è¯¯: {e}")
            st.exception(e)

    # --- Results & Export ---
    if 'results_list' in st.session_state and st.session_state['results_list']:
        st.divider()
        st.subheader("ç”Ÿæˆç»“æœ")
        
        # Convert list to DF for logic
        results_df = pd.DataFrame(st.session_state['results_list'])
        
        edited_df = st.data_editor(
            results_df,
            num_rows="dynamic",
            use_container_width=True,
            height=400
        )
        
        col1, col2 = st.columns([1, 4])
        with col1:
             # Download
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ç»“æœ (Excel)",
                data=export_excel(edited_df),
                file_name="title_genie_results.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
        with col2:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºå½“å‰ä»»åŠ¡ç»“æœ", help="æ¸…é™¤é¡µé¢ç¼“å­˜å’Œè¿›åº¦ï¼Œå¼€å§‹æ–°ä»»åŠ¡"):
                st.session_state['results_list'] = []
                st.session_state['processed_indices'] = set()
                st.rerun()

if __name__ == "__main__":
    main()
